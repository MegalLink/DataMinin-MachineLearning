{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-12T23:44:20.536148Z","iopub.execute_input":"2023-07-12T23:44:20.536597Z","iopub.status.idle":"2023-07-12T23:44:20.543482Z","shell.execute_reply.started":"2023-07-12T23:44:20.536559Z","shell.execute_reply":"2023-07-12T23:44:20.542538Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### 7 Linear Regression with TensorFlow using the California Housing Dataset\nThe goal of this exercise is to implement a linear regression model using TensorFlow to predict house prices based on the California Housing Dataset. The dataset contains various features such as average income, housing average age, and more. Your task is to build a linear regression model and evaluate its performance.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Fetch the California Housing dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-12T23:44:20.548681Z","iopub.execute_input":"2023-07-12T23:44:20.549080Z","iopub.status.idle":"2023-07-12T23:44:20.561117Z","shell.execute_reply.started":"2023-07-12T23:44:20.549048Z","shell.execute_reply":"2023-07-12T23:44:20.559899Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Load the California Housing Dataset","metadata":{}},{"cell_type":"code","source":"# Fetch the California Housing dataset\nraw = fetch_california_housing()\nX = pd.DataFrame(data=raw['data'], columns=raw['feature_names'])\ny = pd.Series(raw['target'])\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T23:44:20.563296Z","iopub.execute_input":"2023-07-12T23:44:20.563768Z","iopub.status.idle":"2023-07-12T23:44:20.582644Z","shell.execute_reply.started":"2023-07-12T23:44:20.563728Z","shell.execute_reply":"2023-07-12T23:44:20.581210Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T23:44:20.584780Z","iopub.execute_input":"2023-07-12T23:44:20.585116Z","iopub.status.idle":"2023-07-12T23:44:20.629420Z","shell.execute_reply.started":"2023-07-12T23:44:20.585088Z","shell.execute_reply":"2023-07-12T23:44:20.628238Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\ncount  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \nmean       3.870671     28.639486      5.429000      1.096675   1425.476744   \nstd        1.899822     12.585558      2.474173      0.473911   1132.462122   \nmin        0.499900      1.000000      0.846154      0.333333      3.000000   \n25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \nmax       15.000100     52.000000    141.909091     34.066667  35682.000000   \n\n           AveOccup      Latitude     Longitude  \ncount  20640.000000  20640.000000  20640.000000  \nmean       3.070655     35.631861   -119.569704  \nstd       10.386050      2.135952      2.003532  \nmin        0.692308     32.540000   -124.350000  \n25%        2.429741     33.930000   -121.800000  \n50%        2.818116     34.260000   -118.490000  \n75%        3.282261     37.710000   -118.010000  \nmax     1243.333333     41.950000   -114.310000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n      <td>20640.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.870671</td>\n      <td>28.639486</td>\n      <td>5.429000</td>\n      <td>1.096675</td>\n      <td>1425.476744</td>\n      <td>3.070655</td>\n      <td>35.631861</td>\n      <td>-119.569704</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.899822</td>\n      <td>12.585558</td>\n      <td>2.474173</td>\n      <td>0.473911</td>\n      <td>1132.462122</td>\n      <td>10.386050</td>\n      <td>2.135952</td>\n      <td>2.003532</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.499900</td>\n      <td>1.000000</td>\n      <td>0.846154</td>\n      <td>0.333333</td>\n      <td>3.000000</td>\n      <td>0.692308</td>\n      <td>32.540000</td>\n      <td>-124.350000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.563400</td>\n      <td>18.000000</td>\n      <td>4.440716</td>\n      <td>1.006079</td>\n      <td>787.000000</td>\n      <td>2.429741</td>\n      <td>33.930000</td>\n      <td>-121.800000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.534800</td>\n      <td>29.000000</td>\n      <td>5.229129</td>\n      <td>1.048780</td>\n      <td>1166.000000</td>\n      <td>2.818116</td>\n      <td>34.260000</td>\n      <td>-118.490000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.743250</td>\n      <td>37.000000</td>\n      <td>6.052381</td>\n      <td>1.099526</td>\n      <td>1725.000000</td>\n      <td>3.282261</td>\n      <td>37.710000</td>\n      <td>-118.010000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.000100</td>\n      <td>52.000000</td>\n      <td>141.909091</td>\n      <td>34.066667</td>\n      <td>35682.000000</td>\n      <td>1243.333333</td>\n      <td>41.950000</td>\n      <td>-114.310000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Preprocess the data:\n\nNormalize the features using the mean and standard deviation.\n\nSplit the dataset into training and testing sets (e.g., 80% for training, 20% for testing).","metadata":{}},{"cell_type":"code","source":"# Normalize the features using mean and standard deviation\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T23:44:20.630543Z","iopub.execute_input":"2023-07-12T23:44:20.630897Z","iopub.status.idle":"2023-07-12T23:44:20.644924Z","shell.execute_reply.started":"2023-07-12T23:44:20.630868Z","shell.execute_reply":"2023-07-12T23:44:20.643700Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Define the TensorFlow graph:\n\nCreate placeholders for the input features (X) and target variable (y).\n\nCreate variables for the model's weights (W) and bias (b).\n\nDefine the linear regression model using the equation: y_pred = X * W + b.\n\nDefine the loss function as the mean squared error between the predicted values and the true values.\n\nChoose an optimizer (e.g., Gradient Descent) to minimize the loss function.","metadata":{}},{"cell_type":"code","source":"# Convert the input data to float64\nX_train = X_train.astype(np.float64)\ny_train = y_train.astype(np.float64)\nX_test = X_test.astype(np.float64)\ny_test = y_test.astype(np.float64)\n\n# Define the TensorFlow graph\ninput_size = X_train.shape[1]\n\nX = tf.keras.Input(shape=(input_size,), name='X', dtype=tf.float64)\ny = tf.keras.Input(shape=(), name='y', dtype=tf.float64)\n\nW = tf.Variable(tf.random.normal([input_size, 1], dtype=tf.float64), name='weights')\nb = tf.Variable(tf.random.normal([1], dtype=tf.float64), name='bias')\n\ny_pred = tf.matmul(X, W) + b\n\n# Define the loss function\nloss = tf.reduce_mean(tf.square(y_pred - y))\n\n# Choose an optimizer\noptimizer = tf.optimizers.Adam(learning_rate=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T23:48:12.030890Z","iopub.execute_input":"2023-07-12T23:48:12.031686Z","iopub.status.idle":"2023-07-12T23:48:12.073151Z","shell.execute_reply.started":"2023-07-12T23:48:12.031642Z","shell.execute_reply":"2023-07-12T23:48:12.071934Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Train the model:\n\nInitialize TensorFlow session.\n\nInitialize the model's variables.\n\nSet the number of training epochs and the learning rate.\n\nFor each epoch, iterate through the training dataset and update the model's parameters using the optimizer.\n\nPrint the training loss at regular intervals.","metadata":{}},{"cell_type":"code","source":"# Train the model\nnum_epochs = 100\nbatch_size = 32\nnum_batches = len(X_train) // batch_size\n\n@tf.function\ndef train_step(X_batch, y_batch):\n    with tf.GradientTape() as tape:\n        y_pred_batch = tf.matmul(X_batch, W) + b\n        batch_loss = tf.reduce_mean(tf.square(y_pred_batch - y_batch))\n    \n    gradients = tape.gradient(batch_loss, [W, b])\n    optimizer.apply_gradients(zip(gradients, [W, b]))\n    \n    return batch_loss\n\nfor epoch in range(num_epochs):\n    avg_loss = 0.0\n    \n    # Iterate over batches\n    for i in range(num_batches):\n        start_idx = i * batch_size\n        end_idx = (i + 1) * batch_size\n        \n        batch_X = X_train[start_idx:end_idx]\n        batch_y = y_train[start_idx:end_idx]\n        \n        # Run optimization\n        batch_loss = train_step(batch_X, batch_y)\n        \n        avg_loss += batch_loss / num_batches\n    \n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T23:51:03.219247Z","iopub.execute_input":"2023-07-12T23:51:03.219686Z","iopub.status.idle":"2023-07-12T23:52:14.058714Z","shell.execute_reply.started":"2023-07-12T23:51:03.219652Z","shell.execute_reply":"2023-07-12T23:52:14.057493Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch 10/100, Loss: 1.3465\nEpoch 20/100, Loss: 1.3386\nEpoch 30/100, Loss: 1.3388\nEpoch 40/100, Loss: 1.3400\nEpoch 50/100, Loss: 1.3506\nEpoch 60/100, Loss: 1.3388\nEpoch 70/100, Loss: 1.3392\nEpoch 80/100, Loss: 1.3389\nEpoch 90/100, Loss: 1.3384\nEpoch 100/100, Loss: 1.3465\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Evaluate the model:\n\nUse the trained model to make predictions on the test dataset.\n\nCalculate the mean squared error (MSE) between the predicted and true values.\n\nPrint the MSE as a measure of the model's performance.","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\ny_pred_test = tf.matmul(X_test, W) + b\nmse = tf.reduce_mean(tf.square(y_pred_test - y_test))\nmse_value = mse.numpy()\n\nprint(f'\\nMean Squared Error (MSE): {mse_value:.4f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A Mean Squared Error (MSE) value of 1.3135 indicates the average squared difference between the predicted and true values in your regression problem. In the case of house price prediction, a lower MSE value indicates that the predicted house prices are closer to the true prices in the dataset.\n\nA low MSE value suggests that the linear regression model is performing well, and its predictions are relatively close to the true house prices. This is a positive outcome as it means the model is making accurate predictions.","metadata":{}}]}